{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands on Session Langchain  LLM Chatbot Development:\n",
    "Research Telegram  using OpenAI Chatbot\n",
    "Hands-on Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install python requirements\n",
    "#!pip install openai, langchain, telebot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate required library\n",
    "import openai\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.agents import Tool\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.utilities import BingSearchAPIWrapper\n",
    "from langchain.agents.conversational_chat.base import ConversationalChatAgent\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load environment and credential\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('.env')\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "os.environ[\"BING_SUBSCRIPTION_KEY\"] = os.getenv('BING_SUBSCRIPTION_KEY')\n",
    "os.environ[\"BING_SEARCH_URL\"] = os.getenv('BING_SEARCH_URL')\n",
    "os.environ[\"TELEGRAM_BOT_KEY\"] = os.getenv('TELEGRAM_BOT_KEY')\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "openai.api_base = os.getenv(\"RESOURCE_ENDPOINT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create embedding, split character and minimize the size to the first 10 document in the paper PDF\n",
    "\n",
    "#from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "#from langchain.document_loaders import UnstructuredPDFLoader\n",
    "#from langchain.document_loaders import OnlinePDFLoader\n",
    "#from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "#loader = OnlinePDFLoader(\"https://arxiv.org/pdf/2304.08485.pdf\", )\n",
    "#loader = UnstructuredPDFLoader(\"docs/2303.18223.pdf\")\n",
    "#docs = loader.load()\n",
    "#text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "#docs = text_splitter.split_documents(docs)\n",
    "#docs = docs[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate OpenAI Embeddings (cost incurred)\n",
    "embeddings = OpenAIEmbeddings(\n",
    "   deployment='Embedding_ada_002',\n",
    "  openai_api_version=os.getenv(\"API_VERSION_ADA\"),\n",
    "  openai_api_base=os.getenv(\"RESOURCE_ENDPOINT_ADA\"),\n",
    "  openai_api_type=\"azure\",\n",
    "  openai_proxy=None,\n",
    "  embedding_ctx_length=8191,\n",
    "  openai_api_key=os.getenv('AZURE_OPENAI_API_KEY_ADA'),\n",
    "  chunk_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save paper embedding\n",
    "#db = FAISS.from_documents(docs, embeddings)\n",
    "#with open('paper_embedding.p', 'wb') as f:\n",
    "    #dump information to that file\n",
    "    #pickle.dump(db, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Windows User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load paper embedding\n",
    "with open('paper_embedding.p', 'rb') as f:\n",
    "    db = pickle.load(f)\n",
    "    db.embedding_function = embeddings.embed_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For MacOS or Unix User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Load paper embedding\n",
    "# with open('paper_embedding_2.p', 'rb') as f:\n",
    "#     db = pickle.load(f)\n",
    "#     db.embedding_function = embeddings.embed_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate LLM, QA Retriever and BingSearch API Tools\n",
    "llm = AzureChatOpenAI(deployment_name=\"ChatGPT_DSC_2\", openai_api_version=\"2023-08-01-preview\",\n",
    "                  temperature=0, openai_api_base=openai.api_base, verbose=True)\n",
    "retriever = db.as_retriever()\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
    "search = BingSearchAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate tools consisting of Retrieval QA and BingSearch\n",
    "tools = [\n",
    "        Tool(\n",
    "            name=\"Paper QA\",\n",
    "            func=qa.run,\n",
    "            description=\"Useful when human have questions about 'the paper' or mention 'the paper' in the input. Any question regarding paper will use this tools. Action input is human question.\",\n",
    "        ),\n",
    "        Tool(name=\"Internet Search\",\n",
    "            func=search.run,\n",
    "            description=\"Only useful when human ask you to search internet and search regarding research. Only use tool when the human mention 'internet'\",\n",
    "        )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate simple prompt template\n",
    "template = \"\"\"You are a chatbot helping human to research paper using the \"Paper QA\" tools.\n",
    "TOOLS:\n",
    "-------------\n",
    "You have access to the following tools:\n",
    "\n",
    "{chat_history}\n",
    "Human: {input}\n",
    "Chatbot:\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"input\",\"agent_scratchpad\"], template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate memory, agent and agent chain to converse with the chatbot\n",
    "memory = ConversationBufferWindowMemory(memory_key=\"chat_history\", k=3, return_messages=True)\n",
    "agent = ConversationalChatAgent.from_llm_and_tools(llm=llm, prompt=prompt, tools=tools, memory=memory, verbose=True)\n",
    "agent_chain = AgentExecutor(agent=agent, tools=tools, llm=llm, verbose=True, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Paper QA\",\n",
      "    \"action_input\": \"Who are the authors of the paper?\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe authors of the paper are Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"The authors of the paper are Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The authors of the paper are Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example questions\n",
    "agent_chain.run(input=\"Who are the authors of the paper?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain.run(input=\"Summarize the paper for me\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain.run(input=\"Search for LLM or Large Language Model in the internet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate telegram bot instance using Telebot\n",
    "# Need to talk to @BotFather on Telegram to create Bot API.\n",
    "# In this hands on session there is one instance already created @askthepaperbot, so no need to run this part\n",
    "# After that you can run the agent and talk with the ResearchGPT Chatbot in Telegram\n",
    "\n",
    "import telebot\n",
    "\n",
    "bot = telebot.TeleBot(os.getenv('TELEGRAM_BOT_KEY'))\n",
    "\n",
    "def generate_answer(text):\n",
    "    try:\n",
    "        result = agent_chain.run(input=text)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Maaf!! Ada error terkait: {e}\"\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "@bot.message_handler(content_types=['text'])\n",
    "def send_text(message):\n",
    "    answer = generate_answer(message.text)\n",
    "    bot.send_message(message.chat.id, answer)\n",
    "\n",
    "bot.polling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
